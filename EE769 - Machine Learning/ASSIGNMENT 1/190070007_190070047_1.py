# -*- coding: utf-8 -*-
"""EE769_Assignment1_Final.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1SkDS9rOHCvxK7GbAVXIxwyPQrPDmDENm

#**EE769 Introduction to Machine Learning**

#Assignment 1: Gradient Descent, Linear Regression, and Regularization


**Template and Instructions**



1. Up to two people can team up, but only one should submit, and both should understand the entire code.
2. Every line of code should end in a comment explaining the line
3. It is recommended to solve the assignment in Google Colab.
Write your roll no.s separated by commas here: 190070007, 190070047
4. Write your names here: Aniket Gupta, Prasann Viswanathan
5. There are two parts to the assignment. In the Part 1, the code format has to be strictly followed to enable auto-grading. In the second part, you can be creative.
6. **You can discuss with other groups or refer to the internet without being penalized, but you cannot copy their code and modify it. Write every line of code and comment on your own.**

#**Part 1 begins ...**
**Instructions to be strictly followed:**

1. Do not add any code cells or markdown cells until the end of this part. Especially, do not change the blocks that say "TEST CASES, DO NOT CHANGE"
2. In all other cells only add code where it says "CODE HERE".
3. If you encounter any raise NotImplementedError() calls you may comment them out.

We cannot ensure correct grading if you change anything else, and you may be penalised for not following these instructions.

## Import Statements
"""

import numpy as np
import pandas as pd
from matplotlib import pyplot as plt

"""## Normalize function 


"""

def Normalize(X): # Output should be a normalized data matrix of the same dimension
    '''
    Normalize all columns of X using mean and standard deviation
    '''
    # YOUR CODE HERE
    X = X-np.mean(X, axis=0) #Making all the columns 0 mean by computing mean of all columns and then subtracting that
    std = np.sqrt(np.sum(X*X, axis=0)/np.shape(X)[0]) #calculating the std vector/value
    X = X/std #Making std deviation of all columns 1 by computing std deviation of all columns and then dividing the specific columns by that
    return X
    # raise NotImplementedError()

'''
TEST CASES, DO NOT CHANGE
'''
''' case 1 - 1 dimensional array'''
#X=np.array([[1,2,3],[3,4,5],[7,8,9]])
X1=np.array([1,2,3])
np.testing.assert_array_almost_equal(Normalize(X1),np.array([-1.224,  0.      ,  1.224]),decimal=3)
''' case 2 - 2 dimensional array'''
X2=np.array([[4,7,6],[3,8,9],[5,11,10]])
np.testing.assert_array_almost_equal(Normalize(X2),np.array([[ 0.  , -0.980581, -1.372813],[-1.224745, -0.392232,  0.392232],[ 1.224745,  1.372813,  0.980581]]))
''' case 3 - 1 dimensional array with float'''
X3=np.array([5.5,6.7,3.2,6.7])
np.testing.assert_array_almost_equal(Normalize(X3),np.array([-0.017,  0.822, -1.627,  0.822]),decimal=3)

"""## Prediction Function

Given X and w, compute the predicted output. Do not forget to add 1's in X
"""

def Prediction (X, w): # Output should be a prediction vector y
    '''
    Compute Prediction given an input datamatrix X and weight vecor w. Output y = [X 1]w where 1 is a vector of all 1s 
    '''
    # YOUR CODE HERE
    col = [[1] for i in range(np.shape(X)[0])] #column with all 1's in accordance with size of X
    X_with_added_ones = np.hstack((X,col)) #adding the column to the end of X
    y = X_with_added_ones.dot(w) #calculating the prediction value using  matrix multiplication
    return y
    # raise NotImplementedError()

'''
TEST CASES, DO NOT CHANGE
'''
''' case 1 - Known input output matrix and weights 1'''
X1 = np.array([[3,2],[1,1]])
w1 = np.array([2,1,1]) 
np.testing.assert_array_equal(Prediction(X1,w1),np.array([9,4]))

"""## Loss Functions

Code the four  loss functions:

1. MSE loss is only for the error
2. MAE loss is only for the error
3. L2 loss is for MSE and L2 regularization, and can call MSE loss
4. L1 loss is for MSE and L1 regularization, and can call MSE loss
"""

def MSE_Loss (X, t, w, lamda =0): # Ouput should be a single number
    '''
    lamda=0 is a default argument to prevent errors if you pass lamda to a function that doesn't need it by mistake. 
    This allows us to call all loss functions with the same input format.
    
    You are encouraged read about default arguments by yourself online if you're not familiar.
    '''
    # YOUR CODE HERE
    prediction = Prediction(X,w) #the vector of predicted values
    error = t-prediction #the vector containing errors corresponding to each sample
    mse = np.sum(error*error)/np.size(error) #mse is 1/n times the sum of all squared errors, i.e., sum of element-wise square of the error vector
    return mse
    # raise NotImplementedError()

'''
TEST CASES, DO NOT CHANGE
'''
''' case 1 '''
X=np.array([[3,6,5],[4.5,6.6,6]])
t=np.array([4,5.5])
w=np.array([2,-1,0.5,1])
np.testing.assert_almost_equal(MSE_Loss(X,t,w),0.53,decimal=3)

def MAE_Loss (X, t, w, lamda = 0): # Output should be a single number
    # YOUR CODE HERE
    prediction = Prediction(X,w) #the vector of predicted values
    error = t-prediction #the vector containing errors corresponding to each sample
    mae = np.sum(np.abs(error))/np.size(error) #mae is 1/n times the sum of all absolute errors, i.e., sum of element-wise absolute of the error vector
    return mae
    # raise NotImplementedError()

'''
TEST CASES, DO NOT CHANGE
'''
''' case 1 '''
X=np.array([[3,6,5],[4.5,6.6,6]])
t=np.array([4,5.5])
w=np.array([2,-1,0.5,1])
np.testing.assert_almost_equal(MAE_Loss(X,t,w),0.700,decimal=3)

def L2_Loss (X, t, w, lamda): # Output should be a single number based on L2-norm (with sqrt)
    ''' Need to specify what inputs are'''
    # YOUR CODE HERE
    mse = MSE_Loss(X, t, w) #mse value
    w_without_bias = w[:-1] #calculating the weight vector without the bias term
    l2_loss = mse + lamda*np.sqrt(np.sum(w_without_bias*w_without_bias)) #penalizing the L2 norm of the weight vector
    return l2_loss
    # raise NotImplementedError()

'''
TEST CASES, DO NOT CHANGE
'''
''' case 1 '''
X=np.array([[3,6,5],[4.5,6.6,6]])
t=np.array([4,5.5])
w=np.array([2,-1,0.5,1])
np.testing.assert_almost_equal(L2_Loss(X,t,w,0.5),1.675,decimal=3)

def L1_Loss (X, t, w, lamda): # Output should be a single number
    # YOUR CODE HERE
    mse = MSE_Loss(X, t, w) #mse value
    w_without_bias = w[:-1] #calculating the weight vector without the bias term
    l1_loss = mse + lamda*np.sum(np.abs(w_without_bias)) #penalizing the L1 norm of the weight vector
    return l1_loss
    # raise NotImplementedError()

'''
TEST CASES, DO NOT CHANGE
'''
''' case 1 '''
X=np.array([[3,6,5],[4.5,6.6,6]])
t=np.array([4,5.5])
w=np.array([2,-1,0.5,1])
np.testing.assert_almost_equal(L1_Loss(X,t,w,0.5),2.280,decimal=3)

def NRMSE_Metric (X, t, w, lamda=0): # Output should be a single number. RMSE/std_dev(t)
    # YOUR CODE HERE
    mse = MSE_Loss(X,t,w) #calculating the mse
    rmse = np.sqrt(mse) #rmse is the square root of mse
    t_minus_tbar = t-np.mean(t) #target vector with mean subtracted
    std = np.sqrt(np.sum(t_minus_tbar*t_minus_tbar)/np.size(t_minus_tbar)) #calculating the std of "t"
    nrmse = rmse/std #calculating nrmse
    return nrmse
    # raise NotImplementedError()

'''
TEST CASES, DO NOT CHANGE
'''
''' Test case 1 '''
X=np.array([[3,6,5],[4.5,6.6,6]])
t=np.array([4,5.5])
w=np.array([2,-1,0.5,1])
np.testing.assert_almost_equal(NRMSE_Metric(X,t,w,0.5),0.970,decimal=3)

"""## Gradient function
Each Loss function will have its own gradient function:

1. MSE gradient is only for the error
2. MAE gradient is only for the error
3. L2 gradient is for MSE and L2 regularization, and can call MSE gradient
4. L1 gradient is for MSE and L1 regularization, and can call MSE gradient
"""

def MSE_Gradient (X, t, w, lamda=0): # Output should have the same size as w
    # YOUR CODE HERE
    prediction = Prediction(X, w) #computing the vector of predicted values    
    col = [[1] for i in range(np.shape(X)[0])] #column with all 1's in accordance with size of X
    X_with_added_ones = np.hstack((X,col)) #adding the column to the end of X
    mse_grad = (2/np.size(prediction))*np.transpose(prediction-t).dot(X_with_added_ones) #using gradient formula for mse loss
    return mse_grad
    # raise NotImplementedError()

'''
TEST CASES, DO NOT CHANGE
'''
''' case 1 '''
X=np.array([[3,6,5],[4.5,6.6,6]])
t=np.array([4,5.5])
w=np.array([2,-1,0.5,1])
np.testing.assert_array_almost_equal(MSE_Gradient(X,t,w),np.array([2.55, 2.94, 2.9 , 0.4 ]),decimal=3)

def MAE_Gradient (X, t, w, lamda=0): # Output should have the same size as w
    # YOUR CODE HERE
    prediction = Prediction(X, w) #computing the vector of predicted values
    col = [[1] for i in range(np.shape(X)[0])] #column with all 1's in accordance with size of X
    X_with_added_ones = np.hstack((X,col)) #adding the column to the end of X
    mae_grad = (1/np.size(prediction))*np.transpose(np.sign(prediction-t)).dot(X_with_added_ones) #using gradient formula for mae loss
    return mae_grad
    # raise NotImplementedError()

'''
TEST CASES, DO NOT CHANGE
'''
''' case 1 '''
X=np.array([[3,6,5],[4.5,6.6,6]])
t=np.array([4,5.5])
w=np.array([2,-1,0.5,1])
np.testing.assert_array_almost_equal(MAE_Gradient(X,t,w),np.array([0.75,  0.3 ,  0.5 , 0.]),decimal=3)

def L2_Gradient (X, t, w, lamda): # Output should have the same size as w
    # YOUR CODE HERE
    mse_grad = MSE_Gradient(X, t, w) #gradient of the mse term in l2 loss
    w_without_bias = w[:-1] #calculating the weight vector without the bias term
    L2_norm = np.sqrt(np.sum(w_without_bias*w_without_bias)) #L2 norm of the weight vector without the bias term
    l2_grad = lamda*w_without_bias/L2_norm #calculating the gradient for the l2 regularization part
    l2_grad = np.append(l2_grad, 0) #adding 0 as it is the derivative of the regularization term with respect to the bias term
    
    return mse_grad + l2_grad
    # raise NotImplementedError()

'''
TEST CASES, DO NOT CHANGE
'''
''' case 1 '''
X=np.array([[3,6,5],[4.5,6.6,6]])
t=np.array([4,5.5])
w=np.array([2,-1,0.5,1])
np.testing.assert_array_almost_equal(L2_Gradient(X,t,w,0.5),np.array([2.986, 2.721, 3.009 , 0.4 ]),decimal=3)

def L1_Gradient (X, t, w, lamda): # Output should have the same size as w
    # YOUR CODE HERE
    mse_grad = MSE_Gradient(X, t, w) #gradient of the mse term in l1 loss
    w_without_bias = w[:-1] #calculating the weight vector without the bias term
    l1_grad = lamda*np.sign(w_without_bias) #calculating the gradient for the l1 regularization part
    l1_grad = np.append(l1_grad, 0) #adding 0 as it is the derivative of the regularization term with respect to the bias term
   
    return mse_grad + l1_grad
    # raise NotImplementedError()

'''
TEST CASES, DO NOT CHANGE
'''
''' case 1 '''
X=np.array([[3,6,5],[4.5,6.6,6]])
t=np.array([4,5.5])
w=np.array([2,-1,0.5,1])
np.testing.assert_array_almost_equal(L1_Gradient(X,t,w,0.5),np.array([3.05, 2.44, 3.4 , 0.4 ]),decimal=3)

"""## Gradient Descent Function

"""

def Gradient_Descent (X, X_val, t, t_val, w, lamda, max_iter, epsilon, lr, lossfunc, gradfunc): # See output format in 'return' statement
    # YOUR CODE HERE
    prev_loss = lossfunc(X, t, w, lamda) #calculating initial value of loss function

    for i in range(max_iter): #we will iterate for a maximum of max_iter times
      grad = gradfunc(X, t, w, lamda) #computing gradient for given loss function
      update_offset = lr*grad #computing the offset by which to update the weight vector
      new_loss = lossfunc(X, t, w-update_offset, lamda) #calculating the new loss if we were to update the weight vector
      if(np.abs(new_loss-prev_loss)<=epsilon): #if loss does not change by more than epsilon, exit descent
        break
      else: #if loss changes by more than epsilon, perform the descent
        w = w - update_offset #updating the weight vector according to gradient descent (minus sign)
      
      prev_loss = new_loss #new_loss of this iteration becomes prev_loss for next iteration
    
    w_final = w #final weights are the weights after for loop ended
    train_loss_final = lossfunc(X, t, w_final, lamda) #computing final loss on training data
    validation_loss_final = lossfunc(X_val, t_val, w_final, lamda) #computing final loss on validation data
    validation_NRMSE = NRMSE_Metric(X_val, t_val, w_final) #computing nrmse for validation data
    #raise NotImplementedError()
    return w_final, train_loss_final, validation_loss_final, validation_NRMSE #You should return variables structured like this.

'''
TEST CASES, DO NOT CHANGE
'''
X=np.array([[23,24],[1,2]])
t=np.array([4,5])
X_val=np.array([[3,4],[5,6]])
t_val=np.array([3,4])
w=np.array([3,2,1])
results =Gradient_Descent (X, X_val, t, t_val, w, 0.1, 100, 1e-10, 1e-5, L2_Loss,L2_Gradient) 
np.testing.assert_allclose([results[1]],[697.919],rtol =0.05)
np.testing.assert_allclose([results[2]],[20],atol=5) # we expect around 17.5  but some students got 24 which we will also accept
#Instructor Values of results[1] and results [2] are 697.919 and 17.512 respectively

"""## Pseudo Inverse Method

You have to implement a slightly more advanced version, with L2 penalty:

w = (X' X + lambda I)^(-1) X' t.

See, for example: Section 2 of https://web.mit.edu/zoya/www/linearRegression.pdf

Here, the column of 1's in assumed to be included in X
"""

def Pseudo_Inverse (X, t, lamda): # Output should be weight vector
    # YOUR CODE HERE
    col = [[1] for i in range(np.shape(X)[0])] #column with all 1's in accordance with size of X
    X_with_added_ones = np.hstack((X,col)) #adding the column to the end of X
    matrix_1 = X_with_added_ones.T.dot(X_with_added_ones) + lamda*np.identity(np.shape(X_with_added_ones)[-1]) #matrix whose inverse is to be found
    w = np.linalg.inv(matrix_1).dot(X_with_added_ones.T.dot(t)) #using formula for w
    return w
    # raise NotImplementedError()

'''
TEST CASES, DO NOT CHANGE
'''
''' case 1 - other data'''
X=np.array([[3,6,5],[4.5,6.6,6]])
t=np.array([4,5.5])
np.testing.assert_array_almost_equal(Pseudo_Inverse(X,t,0.5),np.array([ 0.491,  0.183,  0.319, -0.002]),decimal=3)

"""#... Part 1 ends Below this you be more creative. Just comment out the lines where you save files (e.g. test predictions).

#**Part 2 begins ...**

**Instructions to be loosely followed (except number 8):**

1. Add more code and text cells between this and the last cell.
2. Read training data from: https://www.ee.iitb.ac.in/~asethi/Dump/TempTrain.csv only. Do not use a local copy of the dataset.
3. Find the best lamda for **MSE+lamda*L2(w)** loss function. Plot training and validation RMSE vs. 1/lamda (1/lamda represents model complexity). Print weights, validation RMSE, validation NRMSE for the best lamda.
4. Find the best lamda for **MSE+lamda*L1(w)** loss function. Plot training and validation RMSE vs. 1/lamda (1/lamda represents model complexity). Print weights, validation RMSE, validation NRMSE for the best lamda.
5. Find the best lamda for the **pseudo-inv method**. Plot training and validation RMSE vs. 1/lamda (1/lamda represents model complexity). Print weights, validation RMSE, validation NRMSE for the best lamda.
6. Write your observations and conclusions.
7. Read test data from: https://www.ee.iitb.ac.in/~asethi/Dump/TempTest.csv only. Do not use a local copy of the dataset. Predict its dependent (missing last column) using the model with the lowest MSE, RMSE, or NRMSE. Save it as a file RollNo1_RollNo2_1.csv.
8. **Disable the prediction csv file saving statement and submit this entire .ipynb file, .py file, and .csv file as a single RollNo1_RollNo2_1.zip file.**
"""

from google.colab import files
uploaded_files = files.upload() #uploading the required files

"""#**Processing Training Data**"""

training_df = pd.read_csv("TempTrain.csv") #loading training data
columns_for_x = training_df.columns.values[:-1] #separating the input feature columns with the cloumn for the target
training_df[columns_for_x] = Normalize(training_df[columns_for_x]) #Normalizing only the input features
display(training_df)

training_frac=0.8 #fraction of data to use for training, keeping rest for validation
n = int(training_frac*len(training_df)) #index from which to split
training_part = pd.DataFrame(training_df[:n+1]) #splitting the data into training part
validation_part = pd.DataFrame(training_df[n+1:]) #splitting the data into validation part

display(training_part)
display(validation_part)

training_x = pd.DataFrame(training_part[columns_for_x]) #separating the features from the target
training_y = pd.DataFrame(training_part['Next_Tmax']) #separating the target from the features

validation_x = pd.DataFrame(validation_part[columns_for_x]) #separating the features from the target
validation_y = pd.DataFrame(validation_part['Next_Tmax']) #separating the target from the features

"""#**Processing Testing Data**"""

testing_x = pd.read_csv("TempTest.csv") #loading testing data
testing_x = Normalize(testing_x) #normalizing the features
display(testing_x)

"""#**Finding a good model using L2 Loss**"""

np.random.seed(2) #setting seed for result reproducability
initial_weights_l2 = np.random.normal(size = len(training_x.columns)+1) #initial weights randomly
max_iter_l2 = 100 #max no of iterations for gradient descent
epsilon_l2 = 1e-3 #epsilon for gradient descent
lr_l2 = 0.1 #learning rate for gradient descent
lamda_vals_l2 = np.logspace(-5,1,num=7) #we will see model performance for these 7 values of lamda

#initializing zero arrays to assign values later
w_final_l2 = np.zeros((len(lamda_vals_l2), np.size(initial_weights_l2))) 
train_loss_final_l2 = np.zeros(len(lamda_vals_l2))
validation_loss_final_l2 = np.zeros(len(lamda_vals_l2))
validation_NRMSE_l2 = np.zeros(len(lamda_vals_l2))
training_RMSE_l2 = np.zeros(len(lamda_vals_l2))
validation_RMSE_l2 = np.zeros(len(lamda_vals_l2))

for i in range(len(lamda_vals_l2)): #running gradient descent for each value of lamda
  w_final_l2[i], train_loss_final_l2[i], validation_loss_final_l2[i], validation_NRMSE_l2[i] = Gradient_Descent(np.squeeze(training_x), np.squeeze(validation_x), np.squeeze(training_y), np.squeeze(validation_y), initial_weights_l2, lamda_vals_l2[i], max_iter_l2, epsilon_l2, lr_l2, L2_Loss, L2_Gradient) #running gradient descent
  training_RMSE_l2[i] = np.sqrt(MSE_Loss(np.squeeze(training_x), np.squeeze(training_y), w_final_l2[i])) #the RMSE on training data after running gradient descent for given lamda
  validation_RMSE_l2[i] = np.sqrt(MSE_Loss(np.squeeze(validation_x), np.squeeze(validation_y), w_final_l2[i])) #the RMSE on validation data after running gradient descent for given lamda

#Plotting Training and Validation RMSE vs 1/lamda
plt.xscale('log')
plt.ylabel('RMSE')
plt.xlabel('Model complexity (1/\u03BB)')
plt.plot(1/lamda_vals_l2, training_RMSE_l2, label = "Training RMSE")
plt.plot(1/lamda_vals_l2, validation_RMSE_l2, label = "Validation RMSE")
plt.legend(loc = "upper right")
plt.title("RMSE for different values of \u03BB, using L2 loss")

print("Validation NRMSE values for different \u03BBs:")
for i in range(len(lamda_vals_l2)):
  print(str(lamda_vals_l2[i]) + ': ' + str(validation_NRMSE_l2[i]))

"""We can see that the lowest RMSE is given by the model corresponding to λ = 0.01. So, we will choose this value of λ. For this value of λ:"""

print('Best value of \u03BB='+str(lamda_vals_l2[4])+'.')
print('Weights:', end=' ')
print(w_final_l2[4])
print('Validation RMSE: '+str(validation_RMSE_l2[4]))
print('Validation NRMSE: '+str(validation_NRMSE_l2[4]))

"""#**Finding a good model using L1 Loss**"""

np.random.seed(2) #setting seed for result reproducability
initial_weights_l1 = np.random.normal(size = len(training_x.columns)+1) #initial weights randomly
max_iter_l1 = 100 #max no of iterations for gradient descent
epsilon_l1 = 1e-3 #epsilon for gradient descent
lr_l1 = 0.1 #learning rate for gradient descent
lamda_vals_l1 = np.logspace(-5,1,num=7) #we will see model performance for these 7 values of lamda

#initializing zero arrays to assign values later
w_final_l1 = np.zeros((len(lamda_vals_l1), np.size(initial_weights_l1))) 
train_loss_final_l1 = np.zeros(len(lamda_vals_l1))
validation_loss_final_l1 = np.zeros(len(lamda_vals_l1))
validation_NRMSE_l1 = np.zeros(len(lamda_vals_l1))
training_RMSE_l1 = np.zeros(len(lamda_vals_l1))
validation_RMSE_l1 = np.zeros(len(lamda_vals_l1))

for i in range(len(lamda_vals_l1)): #running gradient descent for each value of lamda
  w_final_l1[i], train_loss_final_l1[i], validation_loss_final_l1[i], validation_NRMSE_l1[i] = Gradient_Descent(np.squeeze(training_x), np.squeeze(validation_x), np.squeeze(training_y), np.squeeze(validation_y), initial_weights_l1, lamda_vals_l1[i], max_iter_l1, epsilon_l1, lr_l1, L1_Loss, L1_Gradient) #running gradient descent
  training_RMSE_l1[i] = np.sqrt(MSE_Loss(np.squeeze(training_x), np.squeeze(training_y), w_final_l1[i])) #the RMSE on training data after running gradient descent for given lamda
  validation_RMSE_l1[i] = np.sqrt(MSE_Loss(np.squeeze(validation_x), np.squeeze(validation_y), w_final_l1[i])) #the RMSE on validation data after running gradient descent for given lamda

#Plotting Training and Validation RMSE vs 1/lamda
plt.xscale('log')
plt.ylabel('RMSE')
plt.xlabel('Model complexity (1/\u03BB)')
plt.plot(1/lamda_vals_l1, training_RMSE_l1, label = "Training RMSE")
plt.plot(1/lamda_vals_l1, validation_RMSE_l1, label = "Validation RMSE")
plt.legend(loc = "upper right")
plt.title("RMSE for different values of \u03BB, using L1 loss")

print("Validation NRMSE values for different \u03BBs:")
for i in range(len(lamda_vals_l1)):
  print(str(lamda_vals_l1[i]) + ': ' + str(validation_NRMSE_l1[i]))

"""We can see that the lowest RMSE is given by the model corresponding to λ = 0.01. So, we will choose this value of λ. For this value of λ:"""

print('Best value of \u03BB='+str(lamda_vals_l1[3])+'.')
print('Weights:', end=' ')
print(w_final_l1[3])
print('Validation RMSE: '+str(validation_RMSE_l1[3]))
print('Validation NRMSE: '+str(validation_NRMSE_l1[3]))

"""#**Finding a good model using Pseudo-inverse method**"""

np.random.seed(2)
lamda_vals_pi = np.logspace(-5,2,num=8) #we will see model performance for these 8 values of lamda

#initializing zero arrays to assign values later
w_final_pi = np.zeros((len(lamda_vals_pi), len(training_x.columns)+1)) 
training_RMSE_pi = np.zeros(len(lamda_vals_pi))
validation_RMSE_pi = np.zeros(len(lamda_vals_pi))
validation_NRMSE_pi = np.zeros(len(lamda_vals_pi))

for i in range(len(lamda_vals_pi)):
  w_final_pi[i] = Pseudo_Inverse(np.squeeze(training_x), np.squeeze(training_y), lamda_vals_pi[i]) #Running Pseudo-inverse method to find the weights
  training_RMSE_pi[i] = np.sqrt(MSE_Loss(np.squeeze(training_x), np.squeeze(training_y), w_final_pi[i])) #the RMSE on training data after finding weights for given lamda
  validation_RMSE_pi[i] = np.sqrt(MSE_Loss(np.squeeze(validation_x), np.squeeze(validation_y), w_final_pi[i])) #the RMSE on validation data after finding weights for given lamda
  validation_NRMSE_pi[i] = NRMSE_Metric(np.squeeze(validation_x), np.squeeze(validation_y), w_final_pi[i]) #the NRMSE on validation data after finding weights for given lamda

#Plotting Training and Validation RMSE vs 1/lamda
plt.xscale('log')
plt.ylabel('RMSE')
plt.xlabel('Model complexity (1/\u03BB)')
plt.plot(1/lamda_vals_pi, training_RMSE_pi, label = "Training RMSE")
plt.plot(1/lamda_vals_pi, validation_RMSE_pi, label = "Validation RMSE")
plt.legend(loc = "upper right")
plt.title("RMSE for different values of \u03BB, using Pseudo-inverse method")

print("Validation NRMSE values for different \u03BBs:")
for i in range(len(lamda_vals_pi)):
  print(str(lamda_vals_pi[i]) + ': ' + str(validation_NRMSE_pi[i]))

"""We can see that the lowest RMSE is given by the model corresponding to λ = 1e-5. So, we will choose this value of λ. For this value of λ:"""

print('Best value of \u03BB='+str(lamda_vals_pi[0])+'.')
print('Weights:', end=' ')
print(w_final_pi[0])
print('Validation RMSE: '+str(validation_RMSE_pi[0]))
print('Validation NRMSE: '+str(validation_NRMSE_pi[0]))

"""#**Observations and Conclusions**

We can see that using all three methods, we achieved very similar results in terms of NMRSE metric. The NRMSE is low, and the performance is hence satisfactory in all three cases. Also, we can see that on increasing model complexity, we are able to increase performance only uptil a certain point. This matches with the theory that we have been studying. The best model was obtained using L2 loss, and λ = 0.1. I will be using the model obtained using that for the subsequent parts.

#**Using the best model to predict the outputs on validation data**
"""

validation_prediction = Prediction(np.squeeze(validation_x), w_final_l2[4])
validation_actual = np.squeeze(validation_y)
index_arr = [i for i in range(len(validation_actual))]
plt.xlabel('Index')
plt.ylabel('Outputs')
plt.plot(index_arr, validation_prediction, label = 'Predicted output')
plt.plot(index_arr, validation_actual, label = 'Actual output')
plt.title('Comparison of predicted and actual output for validation data')
plt.legend()

e = (validation_prediction-validation_actual)
e = np.sum(e*e) #squared sum of errors
var = validation_actual - np.mean(validation_actual)
var = np.sum(var*var) #variance of data
r2_score = 1-(e/var)
print("R2 score is : "+str(r2_score))

"""Obtained R2 score on validation data : 0.8479"""

plt.plot(validation_actual, validation_prediction)
plt.xlabel('Actual Validation Output')
plt.ylabel('Predicted Validation Output')
plt.title('Predicted vs actual output for validation data')
plt.ylim(5,50)

"""We can see that it is roughly a straight line

#**Predicting the output for the Test Data**
"""

test_prediction = Prediction(np.squeeze(testing_x), w_final_l2[4])
prediction_df = pd.DataFrame(test_prediction, columns = ['Next_Tmax'])
display(prediction_df)
#prediction_df.to_csv('190070007_190070047_1.csv', index=False)

"""#**... Part 2 ends.**

1. Write the name or roll no.s of friends from outside your group with whom you discussed the assignment here (no penalty for mere discussion without copying code): 
2. Write the links of sources on the internet referred here (no penalty for mere consultation without copying code): 
"""